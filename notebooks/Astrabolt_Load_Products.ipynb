{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6FMinFdffHe"
      },
      "source": [
        "# Astrabolt - Load Products\n",
        "\n",
        "This notebook uses **ragstack-ai** and **google-cloud-aiplatform** to connect to Astra DB, create the collections needed, and insert the product catalog with its vector embeddings using gemini multimodal embeeding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyOlOCBffReR"
      },
      "source": [
        "## Install Dependencies, Authenticate, and Create Collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_96ckwgXjv-3",
        "outputId": "178d7d85-ccdf-4688-ccf2-f74b42853290"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform ragstack-ai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvivDjx6Fl7Q",
        "outputId": "c5c91323-ddaf-4c7f-ca0e-f0daab4928db"
      },
      "outputs": [],
      "source": [
        "import getpass, os, requests\n",
        "\n",
        "if \"GCP_PROJECT_ID\" not in os.environ or True:\n",
        "  os.environ[\"GCP_PROJECT_ID\"] = getpass.getpass(\"Provide your GCP Project ID\")\n",
        "\n",
        "if \"ASTRA_DB_ENDPOINT\" not in os.environ or True:\n",
        "  os.environ[\"ASTRA_DB_ENDPOINT\"] = getpass.getpass(\"Provide your Astra DB Endpoint\")\n",
        "\n",
        "if \"ASTRA_DB_TOKEN\" not in os.environ or True:\n",
        "  os.environ[\"ASTRA_DB_TOKEN\"] = getpass.getpass(\"Provide your Astra DB Token\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghDCsYUWkL97",
        "outputId": "963448ea-fcea-4514-bba4-c075bd7a0cb0"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "!gcloud config set project {os.getenv(\"GCP_PROJECT_ID\")}\n",
        "\n",
        "auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUg_i3BjkyG-"
      },
      "outputs": [],
      "source": [
        "from astrapy.db import AstraDB\n",
        "# Initialize our vector db\n",
        "astra_db = AstraDB(token=os.getenv(\"ASTRA_DB_TOKEN\"), api_endpoint=os.getenv(\"ASTRA_DB_ENDPOINT\"))\n",
        "collection_descriptions = astra_db.create_collection(collection_name=\"product_catalog_descriptions\", dimension=1408)\n",
        "collection_images = astra_db.create_collection(collection_name=\"product_catalog_images\", dimension=1408)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTDhJ0-0gBhR"
      },
      "source": [
        "## Download Product Catalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50FTTejNkgRg"
      },
      "outputs": [],
      "source": [
        "PRODUCT_CATALOG_URI=\"https://raw.githubusercontent.com/BestBuyAPIs/open-data-set/master/products.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WoP6POukinA",
        "outputId": "eaa4387f-8b72-41b5-f27c-801d8182f1df"
      },
      "outputs": [],
      "source": [
        "!wget $PRODUCT_CATALOG_URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfIUrVTDkmH8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('products.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "products_slice=data[:1000] #Feel free to modify the size of the dataset as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLhF4nYRgWuM"
      },
      "source": [
        "## Create and Load Vector Embeddings\n",
        "We will first create some helper functions for things such as downloading images, inserting records into Astra DB. And finally we will load the data prom `products_slice` in batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6MtRYJknp52"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "def download_image(image_url): #Downloads images from public bestbuy's URI to local file\n",
        "  try:\n",
        "    response = requests.get(image_url)\n",
        "    response.raise_for_status()  # Raise an exception for error status codes\n",
        "\n",
        "    filename = image_url.rsplit(\"/\", 1)[-1]\n",
        "    # Create the folder if it doesn't exist\n",
        "    folder_path=\"product_images\"\n",
        "    if not os.path.exists(folder_path):\n",
        "      os.makedirs(folder_path)\n",
        "    file_path=f\"product_images/{filename}\"\n",
        "    with open(file_path, \"wb\") as f:\n",
        "      f.write(response.content)\n",
        "      return file_path\n",
        "  except requests.exceptions.HTTPError as err:\n",
        "    if err.response.status_code == 404:\n",
        "        print(\"File not found at the specified URL.\")\n",
        "        return None\n",
        "    else:\n",
        "        print(\"An error occurred:\", err)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yPZmk7NpHxS"
      },
      "outputs": [],
      "source": [
        "def insert_document(collection,document, verbose=0): #loads the document into the specified collection\n",
        "  try:\n",
        "    # add to the AstraDB Vector Database\n",
        "    collection.insert_one(document)\n",
        "  except Exception as error:\n",
        "    # if you've already added this record, skip the error message\n",
        "    error_info = json.loads(str(error))\n",
        "    if error_info[0]['errorCode'] == \"DOCUMENT_ALREADY_EXISTS\" and verbose>0:\n",
        "      print(\"Document already exists in the database.  Skipping.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6xMxXRPqkFu"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatVertexAI\n",
        "\n",
        "llm = ChatVertexAI(project=os.getenv(\"GCP_PROJECT_ID\"), model_name=\"gemini-pro-vision\", region=\"uswest-1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVngnthwkoy5",
        "outputId": "69e47445-7043-44ab-ddf3-3132b78014d8"
      },
      "outputs": [],
      "source": [
        "import tqdm, time\n",
        "from vertexai.preview.vision_models import MultiModalEmbeddingModel, Image\n",
        "\n",
        "model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")\n",
        "multimodalembedding_requests_per_minute=120\n",
        "batch_size=multimodalembedding_requests_per_minute\n",
        "\n",
        "# Process product catalog in batches of 1000\n",
        "for batch_start in tqdm.tqdm(range(0, len(products_slice), batch_size), desc=\"Processing product catalog\"):\n",
        "    batch_products = products_slice[batch_start:batch_start + batch_size]\n",
        "\n",
        "    # Create embeddings for the batch of products\n",
        "    t1 = time.perf_counter()\n",
        "    for product in batch_products:\n",
        "      filename = product['image'].rsplit(\"/\", 1)[-1]\n",
        "      import os.path\n",
        "      if not os.path.exists(f\"product_images/{filename}\"):\n",
        "        product[\"_id\"] = product[\"sku\"]\n",
        "        product[\"description\"] = f'{product[\"name\"]}. {product[\"description\"]}'\n",
        "        product[\"main_category\"] = product[\"category\"][0]\n",
        "        filename=download_image(product['image'])\n",
        "        if filename is not None:\n",
        "          img = Image.load_from_file(filename)\n",
        "          embeddings = model.get_embeddings(image=img, contextual_text=product['description'])\n",
        "        else:\n",
        "          embeddings = model.get_embeddings(contextual_text=product['description'])\n",
        "        product[\"$vector\"] = embeddings.text_embedding\n",
        "        insert_document(collection_descriptions,product)\n",
        "        if filename is not None:\n",
        "          product[\"$vector\"] = embeddings.image_embedding\n",
        "          insert_document(collection_images,product)\n",
        "    #t2 = time.perf_counter()\n",
        "    #if t2-t1<60:\n",
        "    #  time.sleep(60-(t2-t1)) #to stay under GCP's API requests quota\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ITq_k9xg6wJ"
      },
      "source": [
        "## Experiment Querying the Database\n",
        "We'll run a couple of queries using text, and image as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy209OHAuobB",
        "outputId": "847a0038-0322-44eb-ce7e-f77b6b8a60d4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from vertexai.preview.vision_models import MultiModalEmbeddingModel, Image\n",
        "from langchain.schema.messages import HumanMessage\n",
        "\n",
        "model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")\n",
        "\n",
        "# Embed the similar item\n",
        "img = Image.load_from_file('2877554_sa.jpg')\n",
        "embeddings = model.get_embeddings(image=img, contextual_text=\"\")\n",
        "\n",
        "# Perform the vector search against AstraDB Vector\n",
        "documents = collection_images.vector_find(\n",
        "    embeddings.image_embedding,\n",
        "    limit=3,\n",
        ")\n",
        "\n",
        "related_products_csv = \"name, image, price, url\\n\"\n",
        "for doc in documents:\n",
        "  related_products_csv += f\"{doc['name']}, {doc['image']}, {doc['price']}, {doc['url']},\\n\"\n",
        "print(related_products_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hvSg5I4yyFz",
        "outputId": "7878185b-a33c-4bcd-dd76-47723a63fed4"
      },
      "outputs": [],
      "source": [
        "embeddings = model.get_embeddings(contextual_text=\"AudioQuest - Niagara 1200 Low-Z Power Conditioner\")\n",
        "\n",
        "# Perform the vector search against AstraDB Vector\n",
        "documents = collection_descriptions.vector_find(\n",
        "    embeddings.text_embedding,\n",
        "    limit=3,\n",
        ")\n",
        "\n",
        "related_products_csv = \"name, image, price, url\\n\"\n",
        "for doc in documents:\n",
        "  related_products_csv += f\"{doc['name']}, {doc['image']}, {doc['price']}, {doc['url']},\\n\"\n",
        "print(related_products_csv)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WyOlOCBffReR"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
